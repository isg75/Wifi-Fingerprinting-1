# INSTALL AND LOAD PACKAGES-----

# If pacman is missing we install it, then we load libraries
if ("pacman" %in% rownames(installed.packages()) == FALSE) {
  install.packages("pacman")
  } else{
    library(pacman)
    rm(list = ls(all = TRUE))
    p_unload(pacman::p_loaded(), character.only = TRUE)
    pacman::p_load(e1071, plotly, purrr, Metrics, randomForestSRC,
                   caTools, Rfast, TTR, DMwR, ranger, h2o, lubridate, 
                   ggplot2, RMySQL, caret, readr, dplyr, tidyr, rstudioapi)
}

# DIRECTORY 

#### Ignacio: Don't use "=" sign, use arrows
# current_path = getActiveDocumentContext()$path
current_path <- getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
# getwd()

cfolder <- getwd()

#UPLOAD DATA 

ptrain <- paste(cfolder,
                list.files(pattern = "trainingData.csv", recursive = TRUE),
                sep="/")

pval <- paste(cfolder,
              list.files(pattern = "validationData.csv", recursive = TRUE),
              sep = "/")

# Train <- read_csv("Data/trainingData.csv")
Train <- read_csv(ptrain)
# rm(ptrain)
# View(Train)

# Test <- read_csv("Data/validationData.csv")
Test <- read_csv(pval)
# rm(pval)
# View(Test)


#FEATURE ENGINEERING 

#Train set
str(Train[520:529])
str(Test[520:529])

# Train$FLOOR <- as.factor(Train$FLOOR)
# Train$BUILDINGID <- as.factor(Train$BUILDINGID)
# Train$SPACEID <- as.factor(Train$SPACEID)
# Train$RELATIVEPOSITION <- as.factor(Train$RELATIVEPOSITION)
# Train$USERID <- as.factor(Train$USERID)
# Train$PHONEID <- as.factor(Train$PHONEID)
# Train$TIMESTAMP <- as_datetime(Train$TIMESTAMP)

#### Ignacio: A more efficient way:
#### Victor, try to embeed every repetitive task in a single function.
#### This functions, takes a dataframe and sets to factor the rigth columns
#### and to data the timestamp.
#### Input: df
#### Outputs: modified df

prepro <- function(df) {
  col <- c("FLOOR","BUILDINGID","SPACEID","RELATIVEPOSITION","USERID","PHONEID")
  df_2 <- df %>% mutate_at(vars(col),factor)
  df_2$TIMESTAMP <- as_datetime(df_2$TIMESTAMP)
  WAP <- grep("WAP", names(df_2), value=T)  
  replace <- function(x) ifelse(x == 100,-105,x)
  df_2 %>% mutate_all(replace)
  df <- df_2
  return(df)
}

Train <- prepro(Train)
Test <- prepro(Test)

# Test$FLOOR <- as.factor(Test$FLOOR)
# Test$BUILDINGID <- as.factor(Test$BUILDINGID)
# Test$SPACEID <- as.factor(Test$SPACEID)
# Test$RELATIVEPOSITION <- as.factor(Test$RELATIVEPOSITION)
# Test$USERID <- as.factor(Test$USERID)
# Test$PHONEID <- as.factor(Test$PHONEID)
# Test$TIMESTAMP <- as_datetime(Test$TIMESTAMP)

#### Victor: You need to justify the need of merging both datasets.
#Create joined dataset 

#### If you have 3D datasets, why don't use 3D plots?
#plot(Train$LONGITUDE, Train$LATITUDE)
#plot(Test$LONGITUDE, Test$LATITUDE)

##### Add info of the dataset
Train$Set <- "Train"
Test$Set  <- "Test"

DF <- rbind(Train, Test)

g1 <- plot_ly(DF, x = ~LONGITUDE, y = ~LATITUDE, z = ~FLOOR, color = ~Set, colors = c('green', 'red'),
             size = 2) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Longitude'),
                      yaxis = list(title = 'Latitude'),
                      zaxis = list(title = 'FLoor')))

g1

#### Victor: Why you don't filter observations and WAPS? Just simply because
#### you can afford running a model in a few minutes with aid of speciall 
#### algorithms and parallelization? In a real world scenario, you datasets
#### can be around several GB of size. Then, even the best performant algorithms
#### will take a lot of time to train a model!!!! FILTER!!! 

# Getting a sample of the whole dataset for training
s_size <- floor(0.75*nrow(DF))
set.seed(420)
#### Victor: At this stage of the course, why do you use the "sample" function
#### to get a "sample" of your data instead of "createDataPartition"?
#### Do you know what is the difference between both?
inTraining <- sample(seq_len(nrow(DF)), size = s_size)
DF_train <- DF[inTraining,]
DF_test <- DF[-inTraining, ]

#Cross Validation ----

train_control <- trainControl(method="cv", number=10)


#Training + Validation -----
#BUILDING

#df.rg.building <- ranger(BUILDINGID ~ . - LONGITUDE - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train, importance = "permutation")
df.rg.building <- ranger(BUILDINGID ~ . - LONGITUDE - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP - Set, DF_train, importance = "permutation")
#df.pred.building <- predict(df.rg.building, DF_test)
#### Please, check out your error metrics in "train" and "test" sets, otherwise
#### how you can know if your model is suffering from overfitting?
df.pred.building_train <- predict(df.rg.building, DF_train)
df.pred.building_test  <- predict(df.rg.building, DF_test)
#rg.table.building <- table(DF_test$BUILDINGID, df.pred.building$predictions) #1.0 accuracy
rg.cm.building_train <- confusionMatrix(DF_train$BUILDINGID,df.pred.building_train$predictions)
rg.cm.building_test  <- confusionMatrix(DF_test$BUILDINGID,df.pred.building_test$predictions)
print(rg.cm.building_train)
print(rg.cm.building_test)

#### Victor, I don't see the utility of doing such analysis and the reason 
#### is the following: the results of your predictions will depend on your
#### sampling. In other words, if you restrict your sample, to some small
#### area, the WAPS around you will be a subset of the total WAPS. Therefore,
#### when you compute the importance of each WAP in the predictions, it will
#### lead you to consider some WAPs which are good for such small area. If 
#### go to another area, those WAPS will be no longer relevant for your prediction.
#### As an example, you can get the most relevant WAP for wour sample running.
#### the following command:
#### which.max(importance(df.rg.building))
#### However, is really unlikely that every time you will be around this WAP.
importance(df.rg.building)

#Floor RF per building
#### Victor Question: Do the floors have a unique identifier? Then if I tell
#### tell you that I'm in floor 1, can you tell me in which building I am?
#### You need to fix this before runnig a model as otherwise youre results
#### will be misleading.

#df.rg.floor <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train,  importance = "permutation")
df.rg.floor <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP - Set, DF_train,  importance = "permutation")
#pred.rg.floor <- predict(df.rg.floor, DF_test)
pred.rg.floor_train <- predict(df.rg.floor, DF_train)
pred.rg.floor_test  <- predict(df.rg.floor, DF_test)
#rg.table.floor <- table(DF_test$FLOOR, pred.rg.floor$predictions) #0.99 accuracy
rg.cm.floor_train <- confusionMatrix(DF_train$FLOOR, pred.rg.floor_train$predictions)
rg.cm.floor_test  <- confusionMatrix(DF_test$FLOOR,  pred.rg.floor_test$predictions)

print(rg.cm.floor_train)
print(rg.cm.floor_test)

#B0

#### Victor: Why do you filter by B0? What is the purpose of doing that?
#### Does your smartphone know in which building it is? What kind of info
#### is gathering the smartphone? 
#### If you want to use models specific for building, then you need to 
#### use the "predicted building" as another predictor NOT the "real building" as otherwise
#### you force the user to provide the real building to the model. 
#### In addition, you are in the risk of making a mistake in the predicted
#### building, and therefore, everything else will be wrong.
#### In fact, what you can do is to check out how many mistakes does your
#### current model in each building not only looking the confussion matrix,
#### just plotting the location where your model have correct and incorrect
#### predictions. 

# DF_train_b0 <- DF_train %>%
#   filter(BUILDINGID == 0)
# DF_train_b0 <- DF_train_b0[sample(1:nrow(DF_train_b0), nrow(DF_train_b0)*0.25,replace=FALSE),]
# DF_test_b0 <- DF_test %>%
#   filter(BUILDINGID == 0)
# DF_train_b0$FLOOR <- droplevels(DF_train_b0$FLOOR)
# DF_test_b0$FLOOR <- droplevels(DF_test_b0$FLOOR)


# rg.b0 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train_b0,  importance = "permutation")
# pred.rg.b0 <- predict(rg.b0, DF_test_b0)
# rg.table.b0 <- table(DF_test_b0$FLOOR, pred.rg.b0$predictions) #0.99 accuracy
# print(confusionMatrix(rg.table.b0))


#B1

# DF_train_b1 <- DF_train %>%
#   filter(BUILDINGID == 1)
# DF_train_b1 <- DF_train_b1[sample(1:nrow(DF_train_b1), nrow(DF_train_b1)*0.25,replace=FALSE),]
# DF_test_b1 <- DF_test %>%
#   filter(BUILDINGID == 1)
# DF_train_b1$FLOOR <- droplevels(DF_train_b1$FLOOR)
# DF_test_b1$FLOOR <- droplevels(DF_test_b1$FLOOR)
# 
# rg.b1x <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train,  importance = "permutation")
# pred.rg.b1x <- predict(rg.b1x, DF_test_b1)
# rg.table.b1x <- table(DF_test_b1$FLOOR, pred.rg.b1x$predictions) #0.99 accuracy
# print(confusionMatrix(rg.table.b1x))



#B2

# DF_train_b2 <- DF_train %>%
#   filter(BUILDINGID == 2)
# DF_train_b2 <- DF_train_b2[sample(1:nrow(DF_train_b2), nrow(DF_train_b2)*0.25,replace=FALSE),]
# DF_test_b2 <- DF_test %>%
#   filter(BUILDINGID == 2)
# DF_train_b2$FLOOR <- droplevels(DF_train_b2$FLOOR)
# 
# 
# rg.b2 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train_b2,  importance = "permutation")
# pred.rg.b2 <- predict(rg.b2, DF_test_b2)
# rg.table.b2 <- table(DF_test_b2$FLOOR, pred.rg.b2$predictions) #0.99 accuracy
# print(confusionMatrix(rg.table.b2))




#LAT/LON


#rg.lon <- ranger(LONGITUDE ~ . - FLOOR - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train,  importance = "permutation")
rg.lon <- ranger(LONGITUDE ~ . - FLOOR - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP - Set, DF_train,  importance = "permutation")
#pred.lon <- predict(rg.lon, DF_test)
pred.lon_train <- predict(rg.lon, DF_train)
pred.lon_test  <- predict(rg.lon, DF_test)

pred.lon_train_metrics <- postResample(pred.lon_train$predictions, DF_train$LONGITUDE)
pred.lon_test_metrics  <- postResample(pred.lon_test$predictions,  DF_test$LONGITUDE)

mape(DF_train$LONGITUDE, pred.lon_train$predictions)
mape(DF_test$LONGITUDE,  pred.lon_test$predictions)

mae(DF_train$LONGITUDE, pred.lon_train$predictions)
mae(DF_test$LONGITUDE,  pred.lon_test$predictions)

#### Latitude

#rg.lat <- ranger(LATITUDE ~ .  - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF_train,  importance = "permutation")
rg.lat <- ranger(LATITUDE ~ .  - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP - Set, DF_train,  importance = "permutation")
pred.lat_train <- predict(rg.lat, DF_train)
pred.lat_test  <- predict(rg.lat, DF_test)

pred.lat_train_metrics <- postResample(pred.lat_train$predictions, DF_train$LATITUDE)
pred.lat_test_metrics  <- postResample(pred.lat_test$predictions, DF_test$LATITUDE)

mape(DF_train$LATITUDE, pred.lat_train$predictions)
mape(DF_test$LATITUDE, pred.lat_test$predictions)

mae(DF_train$LATITUDE, pred.lat_train$predictions)
mae(DF_test$LATITUDE, pred.lat_test$predictions)

# #Val only
#### Victor: What are you doing here? You already used the validation set!!!
# DF.val <- Test
# s_size <- floor(0.75*nrow(DF.val))
# set.seed(420)
# inTraining <- sample(seq_len(nrow(DF.val)), size = s_size)
# DF.val_train <- DF.val[inTraining,]
# DF.val_test <- DF.val[-inTraining, ]
# 
# 
# df.val.rg.building <- ranger(BUILDINGID ~ . - LONGITUDE - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train, importance = "permutation")
# df.val.pred.building <- predict(df.val.rg.building, DF.val_test)
# rg.val.table.building <- table(DF.val_test$BUILDINGID, df.val.pred.building$predictions) #1.0 accuracy
# print(confusionMatrix(rg.val.table.building))
# 
# df.val.rg.floor <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train, importance = "permutation")
# df.val.pred.floor <- predict(df.val.rg.floor, DF.val_test)
# rg.val.table.floor <- table(DF.val_test$FLOOR, df.val.pred.floor$predictions) #0.9 accuracy
# print(confusionMatrix(rg.val.table.floor))
# 
# 
# 
# #B0
# 
# DF.val_train_b0 <- DF.val_train %>%
#   filter(BUILDINGID == 0)
# DF.val_test_b0 <- DF.val_test %>%
#   filter(BUILDINGID == 0)
# DF.val_train_b0$FLOOR <- droplevels(DF.val_train_b0$FLOOR)
# DF.val_test_b0$FLOOR <- droplevels(DF.val_test_b0$FLOOR)
# 
# set.seed(420)
# rg.val.b0 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train_b0,  importance = "permutation")
# pred.rg.val.b0 <- predict(rg.val.b0, DF.val_test_b0)
# rg.val.table.b0 <- table(DF.val_test_b0$FLOOR, pred.rg.val.b0$predictions) #0.93 accuracy
# print(confusionMatrix(rg.val.table.b0))
# 
# rf.val.b0 <- train(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, data = DF.val_train_b0, method = "rf", trControl=fitControl, tuneLength = 1)
# pred.rf.val.b0 <- predict(rf.val.b0, DF.val_test_b0)
# 
# #B1
# 
# DF.val_train_b1 <- DF.val_train %>%
#   filter(BUILDINGID == 1)
# DF.val_test_b1 <- DF.val_test %>%
#   filter(BUILDINGID == 1)
# DF.val_train_b1$FLOOR <- droplevels(DF.val_train_b1$FLOOR)
# DF.val_test_b1$FLOOR <- droplevels(DF.val_test_b1$FLOOR)
# 
# set.seed(420)
# rg.val.b1 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train_b1,  importance = "permutation")
# pred.rg.val.b1 <- predict(rg.val.b1, DF.val_test_b1)
# rg.val.table.b1 <- table(DF.val_test_b1$FLOOR, pred.rg.val.b1$predictions) #0.86 accuracy
# print(confusionMatrix(rg.val.table.b1))
# 
# DF.bullshit <- DF.val_train_b1 %>%
#   select(-c(LONGITUDE, LATITUDE, SPACEID, RELATIVEPOSITION, USERID, PHONEID, TIMESTAMP))
# system.time(rf.val.b1 <-train(FLOOR ~ ., data = DF.bullshit, method = "rf", trControl=train_control, tuneLength = 1))
# system.time(pred.rf.val.b1 <- predict(rf.val.b1, DF.val_test_b1))
# rf.val.table.b1 <- table(DF.val_test_b1$FLOOR, pred.rf.val.b1) #0.88 accuracy
# print(confusionMatrix(rf.val.table.b1))
# 
# #B2
# 
# DF.val_train_b2 <- DF.val_train %>%
#   filter(BUILDINGID == 2)
# DF.val_test_b2 <- DF.val_test %>%
#   filter(BUILDINGID == 2)
# DF.val_train_b2$FLOOR <- droplevels(DF.val_train_b2$FLOOR)
# DF.val_test_b2$FLOOR <- droplevels(DF.val_test_b2$FLOOR)
# 
# set.seed(420)
# rg.val.b2 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train_b2,  importance = "permutation")
# pred.rg.val.b2 <- predict(rg.val.b2, DF.val_test_b2)
# rg.val.table.b2 <- table(DF.val_test_b2$FLOOR, pred.rg.val.b2$predictions) #0.85 accuracy
# print(confusionMatrix(rg.val.table.b2))
# 
# 
# #LON
# set.seed(420)
# rg.val.lon <- ranger(LONGITUDE ~ . - FLOOR - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lon <- predict(rg.val.lon, DF.val_test)
# 
# postResample(pred.val.lon$predictions, DF.val_test$LONGITUDE) #8.405 MAE
# postResample(rg.val.lon$predictions, DF.val_train$LONGITUDE)  #8.716 MAE

#### Victor: Error analysis for Longitude

# plot(pred.val.lon$predictions,DF.val_test$LONGITUDE, col = DF.val_test$BUILDINGID,
#      xlab="predicted",ylab="actual")
# abline(a=0,b=1)

#### Good idea to inspect a single variable like longitude. How it should look like
#### if the model doesn't make mistakes?
plot(DF_train$LONGITUDE, pred.lon_train$predictions,col = DF_train$BUILDINGID,      
       xlab="predicted",ylab="actual")
 abline(a=0,b=1)
#### As you can see, there are points for which your model provides very bad
#### predictions. Where are those points? You can't know it with this not 
#### interactive plot. Therefore, use plotly!!!
 
g2 <- plot_ly(DF, x = ~DF_train$LONGITUDE, y = ~pred.lon_train$predictions, 
              color = ~DF_train$BUILDINGID, 
              colors = c('black', 'red','green')) %>% 
              add_markers() %>% 
              layout(title = "Errors in Longitude for the Train set",
                scene = list(
                xaxis = list(title = "Real Longitude"),
                yaxis = list(title = "Predicted Longitude")
                ))
g2 
 
g3 <- plot_ly(DF, x = ~DF_test$LONGITUDE, y = ~pred.lon_test$predictions, 
              color = ~DF_test$BUILDINGID, 
              colors = c('black', 'red','green')) %>% 
  add_markers() %>% 
  layout(title = "Errors in Longitude for the Test set",
         scene = list(
           xaxis = list(title = "Real Longitude"),
           yaxis = list(title = "Predicted Longitude")
         ))
g3 

#### Victor: Why do you don't have such big outliers in the Test set compared
#### with the Train set?

# #LAT
# set.seed(420)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #4.087 MAE
# postResample(rg.val.lat$predictions, DF.val_train$LATITUDE)  #7.765 MAE
# 
# plot(pred.val.lat$predictions, DF.val_test$LATITUDE, col = DF.val_test$BUILDINGID,
#      xlab="predicted",ylab="actual")
# abline(a=0,b=1)
# 
# plot(pred.val.lon$predictions, pred.val.lat$predictions)

#### Victor: Error anlysis for Latitude.

g4 <- plot_ly(DF, x = ~DF_train$LATITUDE, y = ~pred.lat_train$predictions, 
              color = ~DF_train$BUILDINGID, 
              colors = c('black', 'red','green')) %>% 
  add_markers() %>% 
  layout(title = "Errors in Latitude for the Train set",
         scene = list(
           xaxis = list(title = "Real Latitude"),
           yaxis = list(title = "Predicted Latitude")
         ))
g4 

g5 <- plot_ly(DF, x = ~DF_test$LATITUDE, y = ~pred.lat_test$predictions, 
              color = ~DF_test$BUILDINGID, 
              colors = c('black', 'red','green')) %>% 
  add_markers() %>% 
  layout(title = "Errors in Latitude for the Test set",
         scene = list(
           xaxis = list(title = "Real Latitude"),
           yaxis = list(title = "Predicted Latitude")
         ))
g5 

#### Victor: For latitude, you can see some values for which your model allways
#### have problems (outliers) why?
#### In additions, you can clearly see that there are locations in which several
#### building have the same latitude. Any idea on that?

#New ds with differences
#### Victor: It's a good starting point, however. It will be better to know 
#### the total error that your model have.

# PredDiff <- data.frame(LAT = abs(DF.val_test$LATITUDE - pred.val.lat$predictions),
#                        LON = abs(DF.val_test$LONGITUDE - pred.val.lon$predictions),
#                        BUILDING = DF.val_test$BUILDINGID,
#                        FLOOR = DF.val_test$FLOOR)

PredDiff_train <- data.frame(LAT = abs(DF_train$LATITUDE - pred.lat_train$predictions),
                             LON = abs(DF_test$LONGITUDE - pred.lon_train$predictions),
                             BUILDING = DF_train$BUILDINGID,
                             FLOOR = DF_train$FLOOR)

DF_train$ELATITUDE  <- (DF_train$LATITUDE  - pred.lat_train$predictions)
DF_train$ELONGITUDE <- (DF_train$LONGITUDE - pred.lon_train$predictions)

DF_test$ELATITUDE  <- (DF_test$LATITUDE  - pred.lat_test$predictions)
DF_test$ELONGITUDE <- (DF_test$LONGITUDE - pred.lon_test$predictions)

DF_train$ET <- sqrt(DF_train$ELATITUDE**2 + DF_train$ELONGITUDE**2)
DF_test$ET  <- sqrt(DF_test$ELATITUDE**2  + DF_test$ELONGITUDE**2)

# plot(PredDiff$LAT, col = PredDiff$BUILDING,
#      xlab="Instance",ylab="Prediction Error")
# plot(PredDiff$LON, col = PredDiff$BUILDING,
#      xlab="Instance",ylab="Prediction Error")
# 
# plot(PredDiff$LAT, col = PredDiff$FLOOR,
#      xlab="Instance",ylab="Prediction Error")
# plot(PredDiff$LON, col = PredDiff$FLOOR,
#      xlab="Instance",ylab="Prediction Error")

g6 <- plot_ly(DF_train, x = ~LATITUDE, y = ~LONGITUDE, z = ~FLOOR, 
              color = ~BUILDINGID, 
              size = ~20*ET) %>% 
  add_markers() %>% 
  layout(title = "Total errors in the Train set",
         scene = list(
           xaxis = list(title = "Longitude"),
           yaxis = list(title = "Latitude")
         ))
g6

g7 <- plot_ly(DF_train, x = ~LATITUDE, y = ~LONGITUDE, z = ~FLOOR, 
              color = ~BUILDINGID, 
              size = ~20*ET) %>% 
  add_markers() %>% 
  layout(title = "Total errors in the Test set",
         scene = list(
           xaxis = list(title = "Longitude"),
           yaxis = list(title = "Latitude")
         ))
g7


# #BUILDING
# set.seed(420)
# df.tv.rg.building <- ranger(BUILDINGID ~ . - LONGITUDE - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV, importance = "permutation")
# df.tv.pred.building <- predict(df.tv.rg.building, DF.val_test)
# rg.tv.table.building <- table(DF.val_test$BUILDINGID, df.tv.pred.building$predictions) #0.1 accuracy
# print(confusionMatrix(rg.tv.table.building))
# 
# #FLOOR
# set.seed(420)
# df.tv.rg.floor <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV, importance = "permutation")
# df.tv.pred.floor <- predict(df.tv.rg.floor, DF.val_test)
# rg.tv.table.floor <- table(DF.val_test$FLOOR, df.tv.pred.floor$predictions) #0.9424 accuracy
# print(confusionMatrix(rg.tv.table.floor))
# 
# #B0
# 
# DF.TV_train_b0 <- DF.TV %>%
#   filter(BUILDINGID == 0)
# DF.TV_test_b0 <- DF.val_test %>%
#   filter(BUILDINGID == 0)
# DF.TV_train_b0$FLOOR <- droplevels(DF.TV_train_b0$FLOOR)
# DF.TV_test_b0$FLOOR <- droplevels(DF.TV_test_b0$FLOOR)
# 
# set.seed(420)
# rg.TV.b0 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV_train_b0,  importance = "permutation")
# pred.rg.TV.b0 <- predict(rg.TV.b0, DF.TV_test_b0)
# rg.TV.table.b0 <- table(DF.TV_test_b0$FLOOR, pred.rg.TV.b0$predictions) #0.94 accuracy
# print(confusionMatrix(rg.TV.table.b0))
# 
# #B1
# 
# DF.TV_train_b1 <- DF.TV %>%
#   filter(BUILDINGID == 1)
# DF.TV_test_b1 <- DF.val_test %>%
#   filter(BUILDINGID == 1)
# DF.TV_train_b1$FLOOR <- droplevels(DF.TV_train_b1$FLOOR)
# DF.TV_test_b1$FLOOR <- droplevels(DF.TV_test_b1$FLOOR)
# 
# set.seed(420)
# rg.TV.b1 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV_train_b1,  importance = "permutation")
# pred.rg.TV.b1 <- predict(rg.TV.b1, DF.TV_test_b1)
# rg.TV.table.b1 <- table(DF.TV_test_b1$FLOOR, pred.rg.TV.b1$predictions) #0.90 accuracy
# print(confusionMatrix(rg.TV.table.b1))
# 
# #B2
# 
# DF.TV_train_b2 <- DF.TV %>%
#   filter(BUILDINGID == 2)
# DF.TV_test_b2 <- DF.val_test %>%
#   filter(BUILDINGID == 2)
# DF.TV_train_b2$FLOOR <- droplevels(DF.TV_train_b2$FLOOR)
# DF.TV_test_b2$FLOOR <- droplevels(DF.TV_test_b2$FLOOR)
# 
# set.seed(420)
# rg.TV.b2 <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV_train_b2,  importance = "permutation")
# pred.rg.TV.b2 <- predict(rg.TV.b2, DF.TV_test_b2)
# rg.TV.table.b2 <- table(DF.TV_test_b2$FLOOR, pred.rg.TV.b2$predictions) #0.98 accuracy
# print(confusionMatrix(rg.TV.table.b2))
# 
# 
# #LON
# 
# set.seed(420)
# rg.TV.lon <- ranger(LONGITUDE ~ . - FLOOR - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV,  importance = "permutation")
# pred.TV.lon <- predict(rg.TV.lon, DF.val_test)
# 
# postResample(pred.TV.lon$predictions, DF.val_test$LONGITUDE) #7.268 MAE
# postResample(rg.TV.lon$predictions, DF.TV$LONGITUDE)  #7.904 MAE
# 
# plot(pred.TV.lon$predictions,DF.val_test$LONGITUDE, col = DF.val_test$BUILDINGID,
#      xlab="predicted",ylab="actual")
# abline(a=0,b=1)
# 
# 
# 
# #LAT
# set.seed(420)
# rg.TV.lat <- ranger(LATITUDE ~ . - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.TV,  importance = "permutation")
# pred.TV.lat <- predict(rg.TV.lat, DF.val_test)
# 
# postResample(pred.TV.lat$predictions, DF.val_test$LATITUDE) #6.247 MAE
# postResample(rg.TV.lat$predictions, DF.TV$LATITUDE)  #7.025 MAE
# 
# plot(pred.TV.lat$predictions,DF.val_test$LATITUDE, col = DF.val_test$BUILDINGID,
#      xlab="predicted",ylab="actual")
# abline(a=0,b=1)
# 
# 
# 
# PredDiff <- data.frame(LAT = abs(DF.val_test$LATITUDE - pred.TV.lat$predictions),
#                        LON = abs(DF.val_test$LONGITUDE - pred.TV.lon$predictions),
#                        BUILDING = DF.val_test$BUILDINGID,
#                        FLOOR = DF.val_test$FLOOR,
#                        PHONEID = DF.val_test$PHONEID,
#                        USERID = DF.val_test$USERID)
# 
# plot(PredDiff$LAT, col = PredDiff$BUILDING,
#      xlab="Instance",ylab="Prediction Error")
# plot(PredDiff$LON, col = PredDiff$BUILDING,
#      xlab="Instance",ylab="Prediction Error")
# 
# plot(PredDiff$LAT, col = PredDiff$FLOOR,
#      xlab="Instance",ylab="Prediction Error")
# plot(PredDiff$LON, col = PredDiff$FLOOR,
#      xlab="Instance",ylab="Prediction Error")
# 
# 
# table(Train$USERID)
# table(Train$PHONEID)
# 
# 
# plot_ly(type = "scatter3d",
#         x =  Train$LATITUDE,
#         y =  Train$LONGITUDE,
#         z =  Train$FLOOR,
#         mode = 'markers',
#         color = ~Train$PHONEID)





#Seed test -----
#### Victor: If you want to test how your error metrics changes as long as you 
#### change your sample, you need first to generate several random samples.
#### You can do this easilly with the function: createDataPartition
#### Moreover, with a random sample, youi don't have any control of how spread
#### are your samples.

# set.seed(100)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.096 MAE
# 
# set.seed(200)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.164 MAE
# 
# set.seed(300)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.170 MAE
# 
# set.seed(400)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.171 MAE
# 
# set.seed(500)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.175 MAE
# 
# set.seed(600)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.188 MAE
# 
# set.seed(700)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.151 MAE
# 
# set.seed(800)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.191 MAE
# 
# set.seed(900)
# rg.val.lat <- ranger(LATITUDE ~ .   - FLOOR - LONGITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, DF.val_train,  importance = "permutation")
# pred.val.lat <- predict(rg.val.lat, DF.val_test)
# 
# postResample(pred.val.lat$predictions, DF.val_test$LATITUDE) #7.134 MAE
# 
# 
# #Adding Training lines to Validation -----
# 
#             
# LATLONf0 <- Train %>%
#   filter(FLOOR == 0) %>%
#   mutate(WAPs = sum(Train[1:520])) %>%
#   group_by(LATITUDE, LONGITUDE) %>%
#   slice(which.max(WAPs))
# 
# LATLONf1 <- Train %>%
#   filter(FLOOR == 1) %>%
#   mutate(WAPs = sum(Train[1:520])) %>%
#   group_by(LATITUDE, LONGITUDE) %>%
#   slice(which.max(WAPs))
# 
# LATLONf2 <- Train %>%
#   filter(FLOOR == 2) %>%
#   mutate(WAPs = sum(Train[1:520])) %>%
#   group_by(LATITUDE, LONGITUDE) %>%
#   slice(which.max(WAPs))
# 
# LATLONf3 <- Train %>% 
#   filter(FLOOR == 3) %>%
#   mutate(WAPs = sum(Train[1:520])) %>%
#   group_by(LATITUDE, LONGITUDE) %>%
#   slice(which.max(WAPs))
# 
# LATLONf4 <- Train %>%
#   filter(FLOOR == 4) %>%
#   mutate(WAPs = sum(Train[1:520])) %>%
#   group_by(LATITUDE, LONGITUDE) %>%
#   slice(which.max(WAPs))
# 
# LATLON <- bind_rows(LATLONf0, LATLONf1, LATLONf2, LATLONf3, LATLONf4)
# LATLON$WAPs <- NULL
# 
# DF.TV <- bind_rows(DF.val_train, LATLON)
# DF.TV$SPACEID <- as.factor(DF.TV$SPACEID)
# DF.TV$RELATIVEPOSITION <- as.factor(DF.TV$RELATIVEPOSITION)
# DF.TV$USERID <- as.factor(DF.TV$USERID)
# DF.TV$PHONEID <- as.factor(DF.TV$PHONEID)

#Super cool function -----
#### Victor: Yes, this is a very cool function, but you are writing the 
#### same function FOUR times. One for each variable you want to predict.
#### Wouldn't be even cooler if you add the variable you want to predict 
#### as an argument to your function?  

BUILDING <- function(Training, Testing){
  
  Training <- Training %>%   select(-c(LONGITUDE, LATITUDE, FLOOR, SPACEID, RELATIVEPOSITION, USERID, PHONEID, TIMESTAMP))
  
  Model <- list()
  Predictions <- list()
  Metrics <- list()
  
  #RF
  set.seed(420)
  rg.building <- ranger(BUILDINGID ~ . - LONGITUDE - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, Training, importance = "permutation")
  rg.pred.building <- predict(rg.building, Testing)
  rg.table.building <- confusionMatrix(table(Testing$BUILDINGID, rg.pred.building$predictions))
  
  Model[["RF"]] <- rg.building
  Predictions[["RF"]] <- rg.pred.building
  Metrics[["RF"]] <- rg.table.building
  
  #KNN
  set.seed(420)
  knn.building <- train(BUILDINGID ~ ., Training, method = "knn")
  knn.pred.building <- predict(knn.building, Testing)
  knn.table.building <- confusionMatrix(table(Testing$BUILDINGID, knn.pred.building))
  
  Model[["KNN"]] <- knn.building
  Predictions[["KNN"]] <- knn.pred.building
  Metrics[["KNN"]] <- knn.table.building
  
  #SVM
  set.seed(420)
  svm.building <- svm(BUILDINGID ~ ., Training)
  svm.pred.building <- predict(svm.building, Testing)
  svm.table.building <- confusionMatrix(table(Testing$BUILDINGID, svm.pred.building))
  
  Model[["SVM"]] <- svm.building
  Predictions[["SVM"]] <- svm.pred.building
  Metrics[["SVM"]] <- svm.table.building
  
  
  Output <- list(Model, Predictions, Metrics)
  Output
}

FLOOR <- function(Training, Testing){
  
  Training <- Training %>%   select(-c(LONGITUDE, LATITUDE, SPACEID, RELATIVEPOSITION, USERID, PHONEID, TIMESTAMP))
  Training$FLOOR <- droplevels(Training$FLOOR)
  Training$FLOOR <- droplevels(Training$FLOOR)
  
  Model <- list()
  Predictions <- list()
  Metrics <- list()
  
  #RF
  set.seed(420)
  rg.floor <- ranger(FLOOR ~ . - LONGITUDE - LATITUDE - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, Training, importance = "permutation")
  rg.pred.floor <- predict(rg.floor, Testing)
  rg.table.floor <- confusionMatrix(table(Testing$FLOOR, rg.pred.floor$predictions))
  
  Model[["RF"]] <- rg.floor
  Predictions[["RF"]] <- rg.pred.floor
  Metrics[["RF"]] <- rg.table.floor
  
  #KNN
  set.seed(420)
  knn.floor <- train(FLOOR ~ ., Training, method = "knn")
  knn.pred.floor <- predict(knn.floor, Testing)
  knn.table.floor <- confusionMatrix(table(Testing$FLOOR, knn.pred.floor))
  
  Model[["KNN"]] <- knn.floor
  Predictions[["KNN"]] <- knn.pred.floor
  Metrics[["KNN"]] <- knn.table.floor
  
  #SVM
  set.seed(420)
  svm.floor <- svm(FLOOR ~ ., Training)
  svm.pred.floor <- predict(svm.floor, Testing)
  svm.table.floor <- confusionMatrix(table(Testing$FLOOR, svm.pred.floor))
  
  Model[["SVM"]] <- svm.floor
  Predictions[["SVM"]] <- svm.pred.floor
  Metrics[["SVM"]] <- svm.table.floor
  
  
  Output <- list(Model, Predictions, Metrics)
  Output
}

LATITUDE <- function(Training, Testing){
  
  Training <- Training %>%   select(-c(LONGITUDE, FLOOR, SPACEID, RELATIVEPOSITION, USERID, PHONEID, TIMESTAMP))
  
  Model <- list()
  Predictions <- list()
  Metrics <- list()
  
  #RF
  set.seed(420)
  rg.lat <- ranger(LATITUDE ~ . - LONGITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, Training, importance = "permutation")
  rg.pred.lat <- predict(rg.lat, Testing, interval = "predict")
  rg.table.lat <- postResample(rg.pred.lat$predictions, Testing$LATITUDE)
  
  Model[["RF"]] <- rg.lat
  Predictions[["RF"]] <- rg.pred.lat
  Metrics[["RF"]] <- rg.table.lat
  
  #KNN
  set.seed(420)
  knn.lat <- train(LATITUDE ~ ., Training, method = "knn")
  knn.pred.lat <- predict(knn.lat, Testing)
  knn.table.lat <- postResample(knn.pred.lat, Testing$LATITUDE)
  
  Model[["KNN"]] <- knn.lat
  Predictions[["KNN"]] <- knn.pred.lat
  Metrics[["KNN"]] <- knn.table.lat
  
  #SVM
  set.seed(420)
  svm.lat <- svm(LATITUDE ~ ., Training)
  svm.pred.lat <- predict(svm.lat, Testing, interval = "predict")
  svm.table.lat <- postResample(svm.pred.lat, Testing$LATITUDE)
  
  Model[["SVM"]] <- svm.lat
  Predictions[["SVM"]] <- svm.pred.lat
  Metrics[["SVM"]] <- svm.table.lat
  
  
  Output <- list(Model, Predictions, Metrics)
  Output
}

LONGITUDE <- function(Training, Testing){
  
  Training <- Training %>%   select(-c(LATITUDE, FLOOR, SPACEID, RELATIVEPOSITION, USERID, PHONEID, TIMESTAMP))
  
  Model <- list()
  Predictions <- list()
  Metrics <- list()
  
  #RF
  set.seed(420)
  rg.lon <- ranger(LONGITUDE ~ . - LATITUDE - FLOOR - SPACEID - RELATIVEPOSITION - USERID - PHONEID - TIMESTAMP, Training, importance = "permutation")
  rg.pred.lon <- predict(rg.lon, Testing)
  rg.table.lon <- postResample(rg.pred.lon$predictions, Testing$LONGITUDE)
  
  Model[["RF"]] <- rg.lon
  Predictions[["RF"]] <- rg.pred.lon
  Metrics[["RF"]] <- rg.table.lon
  
  #KNN
  set.seed(420)
  knn.lon <- train(LONGITUDE ~ ., Training, method = "knn")
  knn.pred.lon <- predict(knn.lon, Testing)
  knn.table.lon <- postResample(knn.pred.lon, Testing$LONGITUDE)
  
  Model[["KNN"]] <- knn.lon
  Predictions[["KNN"]] <- knn.pred.lon
  Metrics[["KNN"]] <- knn.table.lon
  
  #SVM
  set.seed(420)
  svm.lon <- svm(LONGITUDE ~ ., Training)
  svm.pred.lon <- predict(svm.lon, Testing)
  svm.table.lon <- postResample(svm.pred.lon, Testing$LONGITUDE)
  
  Model[["SVM"]] <- svm.lon
  Predictions[["SVM"]] <- svm.pred.lon
  Metrics[["SVM"]] <- svm.table.lon
  
  
  Output <- list(Model, Predictions, Metrics)
  Output
}

Results <- list()
Results[["BUILDING"]] <- BUILDING(DF.TV, DF.val_test)
Results[["FLOOR"]] <- FLOOR(DF.TV, DF.val_test)
Results[["LATITUDE"]] <- LATITUDE(DF.TV, DF.val_test)
Results[["LONGITUDE"]] <- LONGITUDE(DF.TV, DF.val_test)


#PLOTS ----
#### Victor: I've already shown you how to do so.
#LAT errors
plot(Results[[3]][[2]]$KNN - DF.val_test$LATITUDE, type = "l", col =  "blue")
lines(Results[[3]][[2]]$RF$predictions - DF.val_test$LATITUDE, type = "l", col = "red")

#LON errors
plot(Results[[4]][[2]]$KNN - DF.val_test$LONGITUDE, type = "l", col =  "blue")
lines(Results[[4]][[2]]$RF$predictions - DF.val_test$LONGITUDE, type = "l", col = "red")

#ESQUISSE
library(esquisse)

PredDiff <- data.frame(LAT.KNN <- Results[[3]][[2]]$KNN - DF.val_test$LATITUDE,
                       LAT.RF <- Results[[3]][[2]]$RF$predictions - DF.val_test$LATITUDE,
                       LON.KNN <- Results[[4]][[2]]$KNN - DF.val_test$LONGITUDE,
                       LON.RF <- Results[[4]][[2]]$RF$predictions - DF.val_test$LONGITUDE,
                       B.KNN <- Results[[1]][[2]]$KNN,
                       B.RF <- Results[[1]][[2]]$RF$predictions,
                       B.Test <- DF.val_test$BUILDINGID,
                       F.KNN <- Results[[2]][[2]]$KNN,
                       F.RF <- Results[[2]][[2]]$RF$predictions,
                       F.Test <- DF.val_test$FLOOR,
                       BUILDING = DF.val_test$BUILDINGID,
                       FLOOR = DF.val_test$FLOOR,
                       PHONEID = DF.val_test$PHONEID,
                       USERID = DF.val_test$USERID)


#LAT ERRORS
ggplot(DF.val_test) + aes(x = as.numeric(row.names(PredDiff))) + 
  geom_line(aes(y = PredDiff$LAT.KNN), stat = "identity", col = "#00bfa5", size = 0.75) + 
  geom_line(aes(y = PredDiff$LAT.RF), stat = "identity", col = "#ef6c00", size = 0.75) +
  labs(x = "", y = "MAE", title = "Latitude Errors", subtitle = "KNN vs RF") +
  theme_minimal()

#LON ERRORS
ggplot(DF.val_test) + aes(x = as.numeric(row.names(PredDiff))) + 
  geom_line(aes(y = PredDiff$LON.KNN), stat = "identity", col = "#00bfa5", size = 0.75) + 
  geom_line(aes(y = PredDiff$LON.RF), stat = "identity", col = "#ef6c00", size = 0.75) +
  labs(x = "", y = "MAE", title = "Longitude Errors", subtitle = "KNN vs RF") +
  theme_minimal()



ggplot(Train) +
  aes(x = LATITUDE, y = LONGITUDE) +
  geom_point(size = 1L, colour = "#00bfa5") +
  labs(title = "Train Latitude Longitude") +
  theme_minimal()

ggplot(Test) +
  aes(x = LATITUDE, y = LONGITUDE) +
  geom_point(size = 1L, colour = "#00bfa5") +
  labs(title = "Validation Latitude Longitude") +
  theme_minimal()

#FinalTest -----

#UPLOAD DATA 

FinalTest <- read_csv("Data/Final.csv")
View(FinalTest)



#FEATURE ENGINEERING

#Train set
str(FinalTest[520:529])

FinalTest$FLOOR <- as.factor(FinalTest$FLOOR)
FinalTest$BUILDINGID <- as.factor(FinalTest$BUILDINGID)
FinalTest$SPACEID <- as.factor(FinalTest$SPACEID)
FinalTest$RELATIVEPOSITION <- as.factor(FinalTest$RELATIVEPOSITION)
FinalTest$USERID <- as.factor(FinalTest$USERID)
FinalTest$PHONEID <- as.factor(FinalTest$PHONEID)
FinalTest$TIMESTAMP <- as_datetime(FinalTest$TIMESTAMP)

FinalTest[FinalTest == 100] <- -105




#Model 1 [RF, RF, KNN, KNN] ----
M1.pred.building <- predict(Results[[1]][[1]]$RF, FinalTest)
summary(M1.pred.building$predictions)

M1.FinalTest <- FinalTest
M1.FinalTest$BUILDINGID <- NULL
M1.FinalTest$BUILDINGID <- M1.pred.building$predictions


M1.pred.floor <- predict(Results[[2]][[1]]$RF, M1.FinalTest)
summary(M1.pred.floor$predictions)

M1.pred.lon <- predict(Results[[4]][[1]]$KNN, M1.FinalTest)
summary(M1.pred.lon)

M1.pred.lat <- predict(Results[[3]][[1]]$KNN, M1.FinalTest)
summary(M1.pred.lat)

plot_ly(type = "scatter3d",
        x =  M1.pred.lat,
        y =  M1.pred.lon,
        z =  M1.pred.floor$predictions,
        mode = 'markers',
        color = ~M1.pred.building$predictions)

M1.Predictions <- data.frame(LATITUDE = M1.pred.lat,
                             LONGITUDE = M1.pred.lon,
                       FLOOR = M1.pred.floor$predictions)

write.csv(M1.Predictions,"Data/Results/Model1.csv", row.names = FALSE)

#Model 2 [Train + Validation] ----
M2.pred.building <- predict(df.rg.building, FinalTest)
summary(M2.pred.building$predictions)

M2.FinalTest <- FinalTest
M2.FinalTest$BUILDINGID <- NULL
M2.FinalTest$BUILDINGID <- M2.pred.building$predictions

M2.pred.floor <- predict(df.rg.floor, M2.FinalTest)
summary(M2.pred.floor$predictions)

M2.pred.lon <- predict(rg.lon, M2.FinalTest)
summary(M2.pred.lon$predictions)

M2.pred.lat <- predict(rg.lat, M2.FinalTest)
summary(M2.pred.lat$predictions)

plot_ly(type = "scatter3d",
        x =  M2.pred.lat$predictions,
        y =  M2.pred.lon$predictions,
        z =  M2.pred.floor$predictions,
        mode = 'markers',
        color = ~M2.pred.building$predictions)

M2.Predictions <- data.frame(LATITUDE = M2.pred.lat$predictions,
                             LONGITUDE = M2.pred.lon$predictions,
                             FLOOR = M2.pred.floor$predictions)

write.csv(M2.Predictions,"Data/Results/Model2.csv", row.names = FALSE)


#Model 3 [RF, RF, RF, RF] ----
M3.pred.building <- predict(Results[[1]][[1]]$RF, FinalTest)
summary(M3.pred.building$predictions)

M3.FinalTest <- FinalTest
M3.FinalTest$BUILDINGID <- NULL
M3.FinalTest$BUILDINGID <- M3.pred.building$predictions


M3.pred.floor <- predict(Results[[2]][[1]]$RF, M3.FinalTest)
summary(M3.pred.floor$predictions)

M3.pred.lon <- predict(Results[[4]][[1]]$RF, M3.FinalTest)
summary(M3.pred.lon$predictions)

M3.pred.lat <- predict(Results[[3]][[1]]$RF, M3.FinalTest)
summary(M3.pred.lat$predictions)

plot_ly(type = "scatter3d",
        x =  M3.pred.lat$predictions,
        y =  M3.pred.lon$predictions,
        z =  M3.pred.floor$predictions,
        mode = 'markers',
        color = ~M3.pred.building$predictions)

M3.Predictions <- data.frame(LATITUDE = M3.pred.lat$predictions,
                             LONGITUDE = M3.pred.lon$predictions,
                             FLOOR = M3.pred.floor$predictions)

write.csv(M3.Predictions,"Data/Results/Model3.csv", row.names = FALSE)


#Model 4 [Val only] -----
M4.pred.building <- predict(df.val.rg.building, FinalTest)
summary(M4.pred.building$predictions)

M4.FinalTest <- FinalTest
M4.FinalTest$BUILDINGID <- NULL
M4.FinalTest$BUILDINGID <- M4.pred.building$predictions

M4.pred.floor <- predict(df.val.rg.floor, M4.FinalTest)
summary(M4.pred.floor$predictions)

M4.pred.lon <- predict(rg.val.lon, M4.FinalTest)
summary(M4.pred.lon$predictions)

M4.pred.lat <- predict(rg.val.lat, M4.FinalTest)
summary(M4.pred.lat$predictions)

plot_ly(type = "scatter3d",
        x =  M4.pred.lat$predictions,
        y =  M4.pred.lon$predictions,
        z =  M4.pred.floor$predictions,
        mode = 'markers',
        color = ~M4.pred.building$predictions)

M4.Predictions <- data.frame(LATITUDE = M4.pred.lat$predictions,
                             LONGITUDE = M4.pred.lon$predictions,
                             FLOOR = M4.pred.floor$predictions)

write.csv(M4.Predictions,"Data/Results/Model4.csv", row.names = FALSE)


#Model 5 [KNN, KNN, KNN, KNN] ------
M5.pred.building <- predict(Results[[1]][[1]]$KNN, FinalTest)
summary(M5.pred.building)

M5.FinalTest <- FinalTest
M5.FinalTest$BUILDINGID <- NULL
M5.FinalTest$BUILDINGID <- M5.pred.building


M5.pred.floor <- predict(Results[[2]][[1]]$KNN, M5.FinalTest)
summary(M5.pred.floor)

M5.pred.lon <- predict(Results[[4]][[1]]$KNN, M5.FinalTest)
summary(M5.pred.lon)

M5.pred.lat <- predict(Results[[3]][[1]]$KNN, M5.FinalTest)
summary(M5.pred.lat)

plot_ly(type = "scatter3d",
        x =  M5.pred.lat,
        y =  M5.pred.lon,
        z =  M5.pred.floor,
        mode = 'markers',
        color = ~M5.pred.building)

M5.Predictions <- data.frame(LATITUDE = M5.pred.lat,
                             LONGITUDE = M5.pred.lon,
                             FLOOR = M5.pred.floor)

write.csv(M5.Predictions,"Data/Results/Model5.csv", row.names = FALSE)

#### TO DO: Victor, avoid making so many copies of dataframes. 
#### The "supercool" function is a nice rthing to have. 
#### If you add the preproc function, then you can write your code 
#### writing the corresponding functions. 
####
#### You need step back and think how to reduce your dataset in order 
#### to speed up things. In a real world, the datasets can be so huge 
#### that even with ranger you will spend a lot of time training the
#### model.

